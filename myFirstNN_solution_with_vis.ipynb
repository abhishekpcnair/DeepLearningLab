{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mancinimassimiliano/DeepLearningLab/blob/master/myFirstNN_solution_with_vis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vRcm5D9Pmatv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "fb397304-55ea-4d40-a39c-e980522f1e95"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "# Library needed for visualization purposes\n",
        "from tensorboardcolab import TensorBoardColab\n",
        "\n",
        "# Instantiate visualizer\n",
        "tb = TensorBoardColab(graph_path='./log')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://2959fc26.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D70JB83_IUwE",
        "colab_type": "code",
        "outputId": "1161bbfc-6991-4c29-81db-7311eacda644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "DEVICE='cuda:0'\n",
        "LR=0.1\n",
        "WEIGHT_DECAY = 0.000001 \n",
        "MOMENTUM = 0.9\n",
        "BATCH_SIZE = 256\n",
        "TEST_BATCH_SIZE = 500\n",
        "EPOCHS = 2\n",
        "\n",
        "INPUT_DIM = 784\n",
        "HIDDEN_DIM = 100\n",
        "OUTPUT_DIM = 10\n",
        "\n",
        "VIS_NAME = 'myFirstNN'\n",
        "\n",
        "\n",
        "class MyFirstNetwork(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super(MyFirstNetwork, self).__init__()\n",
        "    self.input_to_hidden = nn.Linear(input_dim, hidden_dim)\n",
        "    self.activation = nn.ReLU()\n",
        "    self.hidden_to_output = nn.Linear(hidden_dim, output_dim)\n",
        "    \n",
        "    self.input_to_hidden.weight.data.normal_(0,0.1)\n",
        "    self.input_to_hidden.bias.data.fill_(0.0)\n",
        "    self.hidden_to_output.weight.data.normal_(0,0.1)\n",
        "    self.hidden_to_output.bias.data.fill_(0.0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.shape[0],-1)\n",
        "    x = self.input_to_hidden(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.hidden_to_output(x)\n",
        "    return x\n",
        "  \n",
        "\n",
        "def get_data(): \n",
        "  transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "  full_training_data = torchvision.datasets.MNIST('.', train=True, download=True, transform=transform) \n",
        "  test_data = torchvision.datasets.MNIST('.', train=False, download=True, transform=transform)\n",
        "  \n",
        "\n",
        "\n",
        "  num_samples = len(full_training_data)\n",
        "  training_samples = int(num_samples*0.5+1)\n",
        "  validation_samples = num_samples - training_samples\n",
        "\n",
        "  training_data, validation_data = torch.utils.data.random_split(full_training_data, [training_samples, validation_samples])\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(training_data, batch_size = BATCH_SIZE, shuffle=True)\n",
        "  val_loader = torch.utils.data.DataLoader(validation_data, batch_size = TEST_BATCH_SIZE, shuffle=False)\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size = TEST_BATCH_SIZE, shuffle=False)\n",
        "  \n",
        "  return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def get_optimizer(net, lr, wd, momentum):\n",
        "  optimizer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "  return optimizer\n",
        "\n",
        "\n",
        "def get_cost_function():\n",
        "  return nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "def test(net, data_loader, cost_function):\n",
        "  net.eval()\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "      # Load data into GPU\n",
        "      inputs = inputs.to(DEVICE)\n",
        "      targets = targets.to(DEVICE)\n",
        "        \n",
        "      # Forward pass\n",
        "      outputs = net(inputs)\n",
        "\n",
        "      # Apply the loss\n",
        "      loss = cost_function(outputs,targets)\n",
        "\n",
        "      # Better print something, no?\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item()\n",
        "      _, predicted = outputs.max(1)\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(net,data_loader,optimizer,cost_function):\n",
        "  net.train()\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "    # Load data into GPU\n",
        "    inputs = inputs.to(DEVICE)\n",
        "    targets = targets.to(DEVICE)\n",
        "      \n",
        "    # Forward pass\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # Apply the loss\n",
        "    loss = cost_function(outputs,targets)\n",
        "\n",
        "    # Reset the optimizer\n",
        "    optimizer.zero_grad()\n",
        "      \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "      \n",
        "    # Update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # Better print something, no?\n",
        "    samples+=inputs.shape[0]\n",
        "    cumulative_loss += loss.item()\n",
        "    _, predicted = outputs.max(1)\n",
        "    cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n",
        "\n",
        "\n",
        "def main():\n",
        "  train_loader, val_loader, test_loader = get_data()\n",
        "  net = MyFirstNetwork(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM).to(DEVICE)\n",
        "  optimizer = get_optimizer(net, LR, WEIGHT_DECAY, MOMENTUM)\n",
        "  cost_function = get_cost_function()\n",
        "\n",
        "  print('Before training:')\n",
        "  train_loss, train_accuracy = test(net, train_loader, cost_function)\n",
        "  val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "  test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "  \n",
        "  # Add values to plots\n",
        "  tb.save_value('Train Loss',VIS_NAME, 0,train_loss)\n",
        "  tb.save_value('Val Loss',VIS_NAME, 0,val_loss)\n",
        "  tb.save_value('Train Accuracy',VIS_NAME, 0,train_accuracy)\n",
        "  tb.save_value('Val Accuracy',VIS_NAME, 0,val_accuracy)\n",
        "    \n",
        "  # Update plots \n",
        "  tb.flush_line(VIS_NAME)\n",
        "  tb.flush_line(VIS_NAME)\n",
        "  \n",
        "  for e in range(EPOCHS):\n",
        "    train_loss, train_accuracy = train(net, train_loader, optimizer, cost_function)\n",
        "    val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "    print('Epoch: {:d}'.format(e+1))\n",
        "    print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "    print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "    print('-----------------------------------------------------')\n",
        "\n",
        "    # Add values to plots\n",
        "    tb.save_value('Train Loss',VIS_NAME, e+1,train_loss)\n",
        "    tb.save_value('Val Loss',VIS_NAME, e+1,val_loss)\n",
        "    tb.save_value('Train Accuracy',VIS_NAME, e+1,train_accuracy)\n",
        "    tb.save_value('Val Accuracy',VIS_NAME, e+1,val_accuracy)\n",
        "    \n",
        "    # Update plots \n",
        "    tb.flush_line(VIS_NAME)\n",
        "    tb.flush_line(VIS_NAME)\n",
        "  \n",
        "  \n",
        "  print('After training:')\n",
        "  train_loss, train_accuracy = test(net, train_loader, cost_function)\n",
        "  val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "  test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "  \n",
        "  # Close the visualizer\n",
        "  #tb.close()\n",
        "\n",
        "main()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before training:\n",
            "\t Training loss 0.00950, Training accuracy 14.85\n",
            "\t Validation loss 0.00484, Validation accuracy 15.02\n",
            "\t Test loss 0.00482, Test accuracy 16.16\n",
            "-----------------------------------------------------\n",
            "Epoch: 1\n",
            "\t Training loss 0.00191, Training accuracy 85.12\n",
            "\t Validation loss 0.00049, Validation accuracy 92.92\n",
            "-----------------------------------------------------\n",
            "Epoch: 2\n",
            "\t Training loss 0.00080, Training accuracy 94.14\n",
            "\t Validation loss 0.00037, Validation accuracy 94.44\n",
            "-----------------------------------------------------\n",
            "After training:\n",
            "\t Training loss 0.00063, Training accuracy 95.44\n",
            "\t Validation loss 0.00037, Validation accuracy 94.44\n",
            "\t Test loss 0.00036, Test accuracy 94.54\n",
            "-----------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KbPG72MbOLmY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}