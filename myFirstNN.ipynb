{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mancinimassimiliano/DeepLearningLab/blob/master/myFirstNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "D70JB83_IUwE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "\n",
        "DEVICE='cuda:0'\n",
        "LR=0.1\n",
        "WEIGHT_DECAY = 0.000001 \n",
        "MOMENTUM = 0.9\n",
        "BATCH_SIZE = 256\n",
        "TEST_BATCH_SIZE = 500\n",
        "EPOCHS = 20\n",
        "\n",
        "INPUT_DIM = 784\n",
        "HIDDEN_DIM = 100\n",
        "OUTPUT_DIM = 10\n",
        "\n",
        "\n",
        "class MyFirstNetwork(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super(MyFirstNetwork, self).__init__()\n",
        "    # TODO: Initialize layers\n",
        "\n",
        "  def forward(self, x):\n",
        "    # TODO: Define forward pass\n",
        "    return x\n",
        "  \n",
        "\n",
        "def get_data(): \n",
        "  # This function is needed to convert the PIL images to Tensors\n",
        "  transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "  # Load MNIST data\n",
        "  full_training_data = None # TODO \n",
        "  test_data = None # TODO\n",
        "  \n",
        "\n",
        "  # Create train test splits\n",
        "  num_samples = len(full_training_data)\n",
        "  training_samples = int(num_samples*0.5+1)\n",
        "  validation_samples = num_samples - training_samples\n",
        "\n",
        "  training_data, validation_data = torch.utils.data.random_split(full_training_data, [training_samples, validation_samples])\n",
        "\n",
        "  # Initialize dataloaders\n",
        "  train_loader = None # TODO\n",
        "  val_loader = None # TODO\n",
        "  test_loader = None # TODO\n",
        "  \n",
        "  return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def get_optimizer(net, lr, wd, momentum):\n",
        "  # TODO: Create and optimizer (hint: have a look at torch.optim; you can retrieve networks params through net.parameters())\n",
        "  return None\n",
        "\n",
        "\n",
        "def get_cost_function():\n",
        "  # TODO: Initialize the loss function (hint: have a look at torch.nn)\n",
        "  return None\n",
        "\n",
        "\n",
        "\n",
        "def test(net, data_loader, cost_function):\n",
        "  net.eval()\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "      # Load data into GPU\n",
        "        \n",
        "      # Forward pass\n",
        "      outputs = None\n",
        "\n",
        "      # Apply the loss\n",
        "      loss = None\n",
        "\n",
        "      # Better print something, no?\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item()\n",
        "      _, predicted = outputs.max(1)\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(net,data_loader,optimizer,cost_function):\n",
        "  net.train()\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "    # Load data into GPU\n",
        "      \n",
        "    # Forward pass\n",
        "    outputs = None\n",
        "\n",
        "    # Apply the loss\n",
        "    loss = None\n",
        "\n",
        "    # Reset the optimizer\n",
        "      \n",
        "    # Backward pass\n",
        "      \n",
        "    # Update parameters\n",
        "\n",
        "    # Better print something, no?\n",
        "    samples+=inputs.shape[0]\n",
        "    cumulative_loss += loss.item()\n",
        "    _, predicted = outputs.max(1)\n",
        "    cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n",
        "\n",
        "\n",
        "def main():\n",
        "  train_loader, val_loader, test_loader = get_data()\n",
        "  net = MyFirstNetwork(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM).to(DEVICE)\n",
        "  optimizer = get_optimizer(net, LR, WEIGHT_DECAY, MOMENTUM)\n",
        "  cost_function = get_cost_function()\n",
        "\n",
        "  print('Before training:')\n",
        "  train_loss, train_accuracy = test(net, train_loader, cost_function)\n",
        "  val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "  test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "\n",
        "  for e in range(EPOCHS):\n",
        "    train_loss, train_accuracy = train(net, train_loader, optimizer, cost_function)\n",
        "    val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "    print('Epoch: {:d}'.format(e+1))\n",
        "    print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "    print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "    print('-----------------------------------------------------')\n",
        "\n",
        "  print('After training:')\n",
        "  train_loss, train_accuracy = test(net, train_loader, cost_function)\n",
        "  val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "  test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}